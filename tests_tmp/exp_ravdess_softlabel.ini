[EXP]
root = ./tests/
name = exp_ravdess_softlabel
runs = 1
epochs = 20
save = True
[DATA]
root_folders = data_roots.ini
databases = ['ravdess', 'emodb', 'softlabel']
softlabel = my_results.csv
softlabel.type = csv
softlabel.absolute_path = True
#tests = ['emovo']
ravdess.split_strategy = test
emodb.split_strategy = train
softlabel.split_strategy = train
emovo = /home/audeering.local/fburkhardt/audb/emovo/1.2.1/fe182b91/
emovo.target_tables = ['emotion.test']
emovo.files_tables = ['files']
emovo.mapping = {'anger':'angry', 'happiness':'happy', 'sadness':'sad', 'neutral':'neutral'}
emovo.rename_speakers = True
emodb = /home/audeering.local/fburkhardt/audb/emodb/1.3.0/fe182b91/
emodb.mapping = {'anger':'angry', 'happiness':'happy', 'sadness':'sad', 'neutral':'neutral'}
emodb.target_tables = ['emotion.categories.train.gold_standard', 'emotion.categories.test.gold_standard']
ravdess = /home/audeering.local/fburkhardt/audb/ravdess/1.1.2/fe182b91
ravdess.mapping = {'anger':'angry', 'happiness':'happy', 'sadness':'sad', 'neutral':'neutral'}
ravdess.target_tables = ['emotion.speech.test', 'emotion.speech.train']
ravdess.max_samples_per_speaker = 20
labels = ['angry', 'happy', 'neutral', 'sad']
target = emotion
[FEATS]
#type = ['os']
type = ['audmodel']
audmodel.model = audmodel
scale = standard
wav2vec.model = /home/audeering.local/fburkhardt/research/wav2vec2-embeddings/wav2vec2-large-robust-ft-swbd-300h 
[MODEL]
#type = xgb
type = mlp
layers = {'l1':1024, 'l2':128}
drop = .4
save = True
[PLOT]
best_model = True
epoch_progression = True
format = png